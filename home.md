---
layout: page
//title: Home
permalink: /
---

<!-- <img style="float:right;margin-top:-10px;margin-left:10px;" src="images/herman3.jpg" alt="Mugshot"> -->
<img style="float:right;margin-left:10px;height:190px;margin-top:5px;margin-right:5px" src="images/herman_scaled_rounded.jpg" alt="Mugshot">

I am currently doing a post-doc at [Toyota Technological Institute](http://www.ttic.edu/) at Chicago, where I am working with [Karen Livescu](http://ttic.uchicago.edu/~klivescu/) and other awesome people on multi-modal machine learning models that combine speech and vision. I completed my PhD at the [University of Edinburgh](http://www.ed.ac.uk/) where I was supervised by [Sharon Goldwater](http://homepages.inf.ed.ac.uk/sgwater/), [Aren Jansen](http://old-site.clsp.jhu.edu/~ajansen/) and [Simon King](http://homepages.inf.ed.ac.uk/simonk/). Before starting my PhD, I worked with [Thomas Niesler](http://dsp.sun.ac.za/~trn/) at [Stellenbosch University](http://www.sun.ac.za/), South Africa.

My main research interests are in machine learning, speech and language processing, and computer vision. I am particularly interested in machine learning methods that can learn from small amounts of labelled data, and in unsupervised methods that can learn directly from raw unlabelled data. Can an algorithm find meaningful units and structures in a corpus of speech audio, with only minimal guidance? How much supervision is required to build a useful speech processing or computer vision system? These questions are central when building language, speech and vision systems in low- and zero-resource settings.

<!-- How can we combine multiple modalities (e.g. speech+vision) to alleviate data requirements?  -->

<!-- So far I have mainly been working on Bayesian and neural network models to solve low-resource speech processing problems. -->

<!-- Welcome to my home page. I am currently a PhD student at the [University of Edinburgh](http://www.ed.ac.uk/), where I am working in the [ILCC](http://www.ilcc.inf.ed.ac.uk/) and [CSTR](http://www.cstr.ed.ac.uk/) institutes within the [School of Informatics](http://www.inf.ed.ac.uk/). I am supervised by [Sharon Goldwater](http://homepages.inf.ed.ac.uk/sgwater/), [Aren Jansen](http://old-site.clsp.jhu.edu/~ajansen/) and [Simon King](http://homepages.inf.ed.ac.uk/simonk/). Before starting my PhD, I worked with [Thomas Niesler](http://dsp.sun.ac.za/~trn/) at the [Department of Electrical and Electronic Engineering](http://www.ee.sun.ac.za/) at [Stellenbosch University](http://www.sun.ac.za/), South Africa. -->

<!-- My main interests are in machine learning, speech processing, natural language processing and signal processing. I'm particularly interested in how much a computer can discover about language with minimal or no supervision. Can a machine that is presented with a large set of unlabelled data learn (some form) of a language? Can an algorithm find meaningful units and structures in a corpus of speech audio, with only minimal guidance? These questions are central when building language and speech processing systems in low- and zero-resource settings. -->

<!-- <a href="m&#x61;&#105;l&#x74;&#111;:{{ site.email }}">[Email]</a>&ensp;
<a href="https://github.com/{{ site.github_username }}">[GitHub]</a>&ensp;
<a href="https://www.linkedin.com/in/{{ site.linkedin_username }}">[LinkedIn]</a>&ensp;
<a href="{{ site.google_scholar }}">[Scholar]</a -->>


<!-- <div style="text-align:center"> -->

<a href="m&#x61;&#105;l&#x74;&#111;:{{ site.email }}"><i class="fa fa-envelope-o" aria-hidden="true"></i> Email</a>&ensp;
<a href="https://github.com/{{ site.github_username }}"><i class="fa fa-github" aria-hidden="true"></i> GitHub</a>&ensp;
<a href="https://www.linkedin.com/in/{{ site.linkedin_username }}"><i class="fa fa-linkedin-square" aria-hidden="true"></i> LinkedIn</a>&ensp;
<a href="{{ site.google_scholar }}"><i class="fa fa-google" aria-hidden="true"></i> Scholar</a>

<!-- </div> -->
