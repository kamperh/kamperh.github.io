---
layout: page
title: Resources
permalink: /resources/
order: 1
---

# Resources

### Code

Most of my code is available on [GitHub](https://github.com/{{ site.github_username }}), as also noted with each of the [publications]({{site.url}}/publications/). Below is a summary of some of the main repositories.

- [bayes_gmm](https://github.com/kamperh/bayes_gmm): Bayesian Gaussian mixture models in Python, as described in [SLT'14]({{site.url}}/papers/kamper+jansen+king+goldwater_slt2014.pdf).
- [speech_correspondence](https://github.com/kamperh/speech_correspondence): Pylearn2 implementation of the correspondence autoencoder, as described in [ICASSP'15](({{site.url}}/papers/kamper+elsner+jansen+goldwater_icassp2015.pdf)).
- [couscous](https://github.com/kamperh/couscous):  Theano code for training Siamese CNNs. We used it in [ICASSP'16]({{site.url}}/papers/kamper+wang+livescu_icassp2016.pdf) for training acoustic word embeddings from speech, as shown in this [complete recipe](https://github.com/kamperh/recipe_swbd_wordembeds).
- [segmentalist](https://github.com/kamperh/segmentalist): Unsupervised word segmentation and clustering of speech in Python. A complete recipe is coming soon.


### Notes

Hopefully someone else might also find these notes useful. Let me know if you find any mistakes or have any comments.

- Gibbs sampling for fitting finite and infinite Gaussian mixture models.
  [[pdf]({{site.url}}/notes/kamper_bayesgmm15.pdf), [code](https://github.com/kamperh/bayes_gmm)]
- Vector and matrix calculus.
  [[pdf]({{site.url}}/notes/kamper_matrixcalculus13.pdf)]


### Invited talks

- MIT, Computer Science and Artificial Intelligence Laboratory, 2016.  
*Unsupervised neural and Bayesian models for zero-resource speech processing.* [[slides]({{site.url}}/slides/kamper_mit2016_talk.pdf)]
- Workshop on Machine Learning in Speech and Language Processing, Spotlight Speaker, 2016.  
*Unsupervised speech processing using acoustic word embeddings.* [[slides]({{site.url}}/slides/kamper_mlslp2016_talk.pdf)]
